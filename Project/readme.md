### PROJECT MEMBERS ###
StdID | Name
------------ | -------------
64181 | Hafiz Ali Hammad Ansari 
62886 | Hassan Dawood
63454 | Rohail Shah

# CONVOLUTION WE WORKED ON #
In the convolution work, we have a channel and a picture boundary. We initially characterize a channel that we need to utilize. We have utilized 6 unique kinds of channels (clarified underneath). At that point utilizing a settled circle arrangement, we gather the sun of the multitude of cells in the scope of the number we need to convolve. We increase that number with the channel and separate it by the number of components that were utilized to convolve (25, 49, and 81 for our situation). By gathering every one of the qualities from the circle we can arrange the information as required and spot it in another 2d exhibit with the goal that the information can be part and prepared. We have utilized a sum of 6 sorts of channels in the undertaking. In the weighted diagrams, we give the cell in the middle the most weight and those on the limit the least weight.

After applying convoluation and filters we have applied various techniques on our datasets techniques we have used are:

 1. Linear Regression
 2. Multimonial Naive Bayes
 3. SVM
 4. KNN

## KNN: ##
The KNN is k-nearest neighbors’ algorithm it is a most unique and simple algo it is also used in machine learning so we can used for both the problems known as classification and regression. The most unique part it is easy to implement and easy to get. But it has a issue it is slow and the size of the data use to grows.

Example: The most common and unique example of KNN is voting system. We can convert it into sub classes and functions like “Vote” and “Not vote”.

## Linear Regression: ##

1.  This model used to minimize the sum of square between the observed and target in the data set and the target predicted by the linear approximation.
2.  By using this model on 5x5, convolution with same filter we achieved 0.603 score.
3.  On 5x5 convolution, with different filter we achieved 0.604 score
4.  Now applying 7x7 convolution, with same filter we achieved 0.603 score.
5.  On 7x7 convolution with different filter, we achieved 0.588 score.
6.  Now applying 9x9 convolution, with same filter we achieved 0.5818 score.
7.  On 9x9 convolution, with different filter we achieved 0.5841.

## SVM: ## 
It is known as support vector machines it is the most solid reliable and observable machine learning algorithm which is used for both function classification and regression. But for most of the time it is used for the classification problems. It got some unique and professional way of in hence implementation as revision to other machine learning algorithm.

## MultinomialNB: ## 
The MultinomialNB Naïve Bayes Classifer is a machine learning model basically used for large amount of data and good for the use of classification with some new techniques of discrete features. If we take MultinomialNB distribution it normally requires numeric count.

## Weighted SVM: **
 Weighted SVM represent this hyper plane to give the coordinates of the vector. These are coefficients given by SVM. AS I read and my understanding first coordinate is used for separation, W will be of the form (x, 0) where x is some non-zero number and then |x|>0. SVM is an observed machine learning algorithm which and it is used for the purpose of classification and regression issues.

## Weighted KNN: ## 
AS we read in the class and (k-NN) is a relatively simple technique to analyze the class of an item based on two or more numeric predictor variables. We can say that for example a person based on his age, annual income, gender, years of education and so on. Other factor that I notice one amongst the various problems that have an effect on the performance of KNN formula is that the selection of the hyper parameter k. If k is simply too tiny, the formula would be additional sensitive to information points that area unit outliers.

## Weighted Multinomial NB: ## 
This method is used multiple times continuously on different platforms of a dataset and it is set to be implement for online learning. When we goes for a big data set this is mostly used for that because it fits for big data memory. This algorithm have some unique performance purposes it is mainly used for big data which easily have possible overhead.

Convulation is acheived by applying it again and again on the test file untill our desired result it obtained i.e. maximum accuracy.

## Contributions: ##
All partners have worked equally
